{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Extracting Images for Transistors from PDF Datasheets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We will walk through the process of using `Fonduer` to extract images from [**richly formatted** data](https://hazyresearch.github.io/snorkel/blog/fonduer.html), where information is conveyed via combinations of textual, structural, tabular, and visual expressions, as seen in webpages, business reports, product specifications, and scientific literature.\n",
    "\n",
    "In this tutorial, we use `Fonduer` to identify mentions of the image of transistors in a corpus of transistor datasheets from [Digikey.com](https://www.digikey.com/products/en/discrete-semiconductor-products/transistors-bipolar-bjt-single/276).\n",
    "\n",
    "The tutorial only contains two parts:\n",
    "\n",
    "1. KBC Initialization\n",
    "2. Candidate Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: KBC Initialization\n",
    "\n",
    "In this first phase of `Fonduer`'s pipeline, `Fonduer` uses a user specified _schema_ to initialize a relational database where the output KB will be stored. Furthermore, `Fonduer` iterates over its input _corpus_ and transforms each document into a unified data model, which captures the variability and multimodality of richly formatted data. This unified data model then servers as an intermediate representation used in the rest of the phases.\n",
    "\n",
    "This preprocessed data is saved to a database. The connection string to the database is provided to the `Meta` object, which will initialize a PostgreSQL database for parallel execution.\n",
    "\n",
    "We initialize several variables for convenience that define what the database should be called and what level of parallelization the `Fonduer` pipeline will be run with.\n",
    "\n",
    "Before you continue, please make sure that you have PostgreSQL installed and have created a new database named `stg_temp_max_figure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Configure logging for Fonduer\n",
    "logging.basicConfig(stream=sys.stdout, format='[%(levelname)s] %(name)s - %(message)s')\n",
    "log = logging.getLogger('fonduer')\n",
    "log.setLevel(logging.INFO)\n",
    "\n",
    "PARALLEL = 4 # assuming a quad-core machine\n",
    "ATTRIBUTE = \"stg_temp_max_figure\"\n",
    "conn_string = 'postgresql://localhost:5432/' + ATTRIBUTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Parsing and Transforming the Input Documents into Unified Data Models\n",
    "\n",
    "We first initialize a `Meta` object, which manages the connection to the database automatically, and enables us to save intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.meta - Connecting user:None to localhost:5432/stg_temp_max_figure\n",
      "[INFO] fonduer.meta - Initializing the storage schema\n"
     ]
    }
   ],
   "source": [
    "from fonduer import Meta\n",
    "\n",
    "session = Meta.init(conn_string).Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Next, we load the corpus of datasheets and transform them into the unified data model. Each datasheet has a PDF and HTML representation (in this example, the HTML is created using Adobe Acrobat). Both representations are used in conjunction to create a robust unified data model with textual, structural, tabular, and visual modality information. Note that since each document is independent of each other, we can parse the documents in parallel. We depend on PostgreSQL for this functionality.\n",
    "\n",
    "### Configuring an `HTMLDocPreprocessor`\n",
    "We start by setting the paths to where our documents are stored, and defining a `HTMLDocPreprocessor` to read in the documents found in the specified paths. `max_docs` specified the number of documents to parse. For the sake of this tutorial, we only look at 100 documents.\n",
    "\n",
    "**Note that you need to have run `download_data.sh` before executing these next steps or you won't have the documents needed for the tutorial.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.parser.preprocessors import HTMLDocPreprocessor\n",
    "from fonduer.parser import Parser\n",
    "\n",
    "docs_path = 'data/html/'\n",
    "pdf_path = 'data/pdf/'\n",
    "\n",
    "max_docs = 4\n",
    "doc_preprocessor = HTMLDocPreprocessor(docs_path, max_docs=max_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring a `Parser`\n",
    "Next, we configure a `Parser`, which serves as our `CorpusParser` for PDF documents. We use [spaCy](https://spacy.io/) as a preprocessing tool to split our documents into sentences and tokens, and to provide annotations such as part-of-speech tags and dependency parse structures for these sentences. In addition, we can specify which modality information to include in the unified data model for each document. Below, we enable all modality information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6d827b68774083aa022871b3e00c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 6.8 s, sys: 764 ms, total: 7.56 s\n",
      "Wall time: 9min 44s\n"
     ]
    }
   ],
   "source": [
    "corpus_parser = Parser(\n",
    "    session, structural=True, lingual=True, visual=True, pdf_path=pdf_path, flatten=[]\n",
    ")\n",
    "corpus_parser.apply(doc_preprocessor, parallelism=PARALLEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use simple database queries (written in the syntax of [SQLAlchemy](http://www.sqlalchemy.org/), which `Fonduer` uses) to check how many documents and sentences were parsed, or even check how many sentences and figures are contained in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 4\n",
      "Sentences: 36562\n",
      "Figures: 450\n"
     ]
    }
   ],
   "source": [
    "from fonduer.parser.models import Document, Sentence, Figure\n",
    "\n",
    "print(f\"Documents: {session.query(Document).count()}\")\n",
    "print(f\"Sentences: {session.query(Sentence).count()}\")\n",
    "print(f\"Figures: {session.query(Figure).count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dividing the Corpus into Test and Train\n",
    "\n",
    "We'll split the documents 2/1/1 into train/dev/test splits. Note that here we do this in a non-random order to preverse the consistency in the tutorial, and we reference the splits by 0/1/2 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lmp2014mt', 'lmp2011']\n"
     ]
    }
   ],
   "source": [
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "ld   = len(docs)\n",
    "\n",
    "train_docs = set()\n",
    "dev_docs   = set()\n",
    "test_docs  = set()\n",
    "splits = (0.5, 0.75)\n",
    "data = [(doc.name, doc) for doc in docs]\n",
    "data.sort(key=lambda x: x[0])\n",
    "for i, (doc_name, doc) in enumerate(data):\n",
    "    if i < splits[0] * ld:\n",
    "        train_docs.add(doc)\n",
    "    elif i < splits[1] * ld:\n",
    "        dev_docs.add(doc)\n",
    "    else:\n",
    "        test_docs.add(doc)\n",
    "from pprint import pprint\n",
    "pprint([x.name for x in train_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Mention Extraction, Candidate Extraction Multimodal Featurization\n",
    "\n",
    "Given the unified data model from Phase 1, `Fonduer` extracts relation\n",
    "candidates based on user-provided **matchers** and **throttlers**. Then,\n",
    "`Fonduer` leverages the multimodality information captured in the unified data\n",
    "model to provide multimodal features for each candidate.\n",
    "\n",
    "## 2.1 Mention Extraction\n",
    "\n",
    "The first step is to extract **mentions** from our corpus. A `mention` is the\n",
    "type of object which makes up a `candidate`. For example, if we wanted to\n",
    "extract pairs of transistor part numbers and their corresponding maximum\n",
    "storage temperatures, the transistor part number would be one `mention` while\n",
    "the temperature value would be another. These `mention`s are then combined to\n",
    "create `candidates`, where our task is to predict which `candidates` are true\n",
    "in the associated document.\n",
    "\n",
    "We first start by defining and naming our `mention`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models import mention_subclass\n",
    "\n",
    "Fig = mention_subclass(\"Fig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write **matchers** to define which spans of text in the corpus are\n",
    "instances of each entity. Matchers can leverage a variety of information from\n",
    "regular expressions, to dictionaries, to user-defined functions. Furthermore,\n",
    "different techniques can be combined to form higher quality matchers. In\n",
    "general, matchers should seek to be as precise as possible while maintaining\n",
    "complete recall. More documentation about Matchers can be found on [Read the Docs](https://fonduer.readthedocs.io/en/stable/user/candidates.html#matchers).\n",
    "\n",
    "In our case, we need to write a matcher that defines a transistor part number\n",
    "and a matcher to identify images in a document.\n",
    "\n",
    "### Writing a image matcher\n",
    "\n",
    "Our image matcher can be a very simple since we want to search all images in the documents. More advanced matchers can be defined by users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.matchers import LambdaFunctionFigureMatcher\n",
    "\n",
    "def do_nothing_matcher(fig):\n",
    "    return True\n",
    "\n",
    "fig_matcher = LambdaFunctionFigureMatcher(func=do_nothing_matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a relation's `MentionSpaces`\n",
    "\n",
    "Next, in order to define the \"space\" of all mentions that are even considered\n",
    "from the document, we need to define a `MentionSpace` for each component of the\n",
    "relation we wish to extract. Fonduer provides a default `MentionSpace` for you\n",
    "to use, but you can also extend the default `MentionSpace` depending on your\n",
    "needs.\n",
    "\n",
    "In the case of transistor images, the `MentionSpace` can be all png images.\n",
    "\n",
    "When no special preproessing like this is needed, we could have used the default `MentionFigures` class provided by `fonduer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates import MentionFigures\n",
    "\n",
    "figs = MentionFigures(types=['png'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Mention Extraction \n",
    "\n",
    "Next, we create a `MentionExtractor` to extract the mentions from all of\n",
    "our documents based on the `MentionSpace` and matchers we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.candidates.mentions - Clearing table: fig\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d6a646659a4b2bbf0c7488eaecd7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Mentions: 353\n"
     ]
    }
   ],
   "source": [
    "from fonduer.candidates import MentionExtractor \n",
    "\n",
    "mention_extractor = MentionExtractor(session, [Fig], [figs], [fig_matcher], parallelism=PARALLEL)\n",
    "\n",
    "from fonduer.candidates.models import Mention\n",
    "\n",
    "mention_extractor.apply(docs)\n",
    "\n",
    "print(f\"Total Mentions: {session.query(Mention).count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Candidate Extraction\n",
    "\n",
    "Now that we have both defined and extracted the Mentions that can be used to compose Candidates, we are ready to move on to extracting Candidates. Like we did with the Mentions, we first define what each candidate schema looks like. In this example, we create a candidate that is composed of just a `Fig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models import candidate_subclass\n",
    "\n",
    "FigCand = candidate_subclass(\"FigCand\", [Fig])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.candidates.candidates - Clearing table fig_cand (split 0)\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56e2c5535eb45a3afe5e338143fba0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 96 ms, sys: 68 ms, total: 164 ms\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "from fonduer.candidates import CandidateExtractor\n",
    "\n",
    "\n",
    "candidate_extractor = CandidateExtractor(session, [FigCand], throttlers=[None], parallelism=PARALLEL)\n",
    "\n",
    "%time candidate_extractor.apply(train_docs, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specified that these `Candidates` belong to the training set by specifying `split=0`; recall that we're referring to train/dev/test as splits 0/1/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 181\n"
     ]
    }
   ],
   "source": [
    "train_cands = session.query(FigCand).filter(FigCand.split == 0).order_by(FigCand.id).all()\n",
    "print(f\"Number of candidates: {len(train_cands)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating for development and test splits\n",
    "Finally, we rerun the same operation for the other two document divisions: dev and test. For each, we simply load the `Corpus` object and run them through the `CandidateExtractor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.candidates.candidates - Clearing table fig_cand (split 1)\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7caa0020751484f9153fb6c9ba8be05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of candidates: 58\n",
      "[INFO] fonduer.candidates.candidates - Clearing table fig_cand (split 2)\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4013b59a9535490a927eae2313393430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of candidates: 114\n",
      "CPU times: user 172 ms, sys: 152 ms, total: 324 ms\n",
      "Wall time: 3.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, docs in enumerate([dev_docs, test_docs]):\n",
    "    candidate_extractor.apply(docs, split=i+1)\n",
    "    print(f\"Number of candidates: {session.query(FigCand).filter(FigCand.split == i+1).count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FigCand(Fig(FigureMention(document=lmp2014mt, position=20, url=lmp2014mt/Image_021.png)))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "n = 33\n",
    "\n",
    "print(train_cands[n])\n",
    "Image(f\"{docs_path}/{train_cands[n][0].context.figure.url}\", format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
